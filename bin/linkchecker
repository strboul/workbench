#!/usr/bin/env bash

# Crawl and parse links on a website
#
# Usage: linkchecker [WEBSITE_LINK]
#
# Sources:
# - https://github.com/linkchecker/linkchecker
# - https://wummel.github.io/linkchecker/
#

set -e

source "$HOME"/dotfiles/bin/__utils/utils.sh

utils__stop_if_not_command_exists "podman"

URL=$1

[ -z "$URL" ] && utils__err_exit "provide an URL"

DIRNAME="$(printf "linkchecker_%s" "$(utils__timestamp | sed 's/ /_/g; s/:/_/g')")"
TMPDIRPAT="/tmp/$DIRNAME/"

mkdir -p "${TMPDIRPAT}"

podman run --rm -it \
  -u "$(id -u)":"$(id -g)" \
  -v "$TMPDIRPAT":/mnt \
  ghcr.io/linkchecker/linkchecker:latest \
  -Fhtml/linkchecker.html \
  -Fcsv/linkchecker.csv \
  --verbose \
  "$URL"

utils__log__info "saved in $TMPDIRPAT"
